{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SVM6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ty4TGpRLE3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e5f5f9-2e3c-48ce-9948-9fcebc3ac08d"
      },
      "source": [
        "pip install torchtuples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtuples\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 30 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 369 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from torchtuples) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from torchtuples) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from torchtuples) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.3->torchtuples) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->torchtuples) (2018.9)\n",
            "Installing collected packages: torchtuples\n",
            "Successfully installed torchtuples-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmMqAiBALUzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8d080e-29a8-47cf-e632-b797e012645d"
      },
      "source": [
        "pip install pycox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycox\n",
            "  Downloading pycox-0.2.2-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 73 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.4.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.22.2.post1)\n",
            "Requirement already satisfied: torchtuples>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.2.2)\n",
            "Collecting py7zr>=0.11.3\n",
            "  Downloading py7zr-0.16.1-py3-none-any.whl (65 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 30 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 40 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 51 kB 41.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 61 kB 45.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pycox) (2.23.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.7/dist-packages (from pycox) (0.51.2)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from feather-format>=0.4.0->pycox) (3.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->pycox) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->pycox) (1.19.5)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.44->pycox) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.44->pycox) (57.4.0)\n",
            "Collecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting bcj-cffi<0.6.0,>=0.5.1\n",
            "  Downloading bcj_cffi-0.5.1-cp37-cp37m-manylinux2014_x86_64.whl (36 kB)\n",
            "Collecting pyppmd>=0.14.0\n",
            "  Downloading pyppmd-0.16.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 36.2 MB/s \n",
            "\u001b[?25hCollecting pyzstd<0.15.0,>=0.14.4\n",
            "  Downloading pyzstd-0.14.4-cp37-cp37m-manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.11.3->pycox) (4.6.4)\n",
            "Requirement already satisfied: cffi>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr>=0.11.3->pycox) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr>=0.11.3->pycox) (2.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pycox) (1.24.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->pycox) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->pycox) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from torchtuples>=0.2.0->pycox) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from torchtuples>=0.2.0->pycox) (1.1.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->py7zr>=0.11.3->pycox) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->py7zr>=0.11.3->pycox) (3.5.0)\n",
            "Installing collected packages: texttable, pyzstd, pyppmd, pycryptodomex, multivolumefile, brotli, bcj-cffi, py7zr, pycox\n",
            "Successfully installed bcj-cffi-0.5.1 brotli-1.0.9 multivolumefile-0.2.3 py7zr-0.16.1 pycox-0.2.2 pycryptodomex-3.10.1 pyppmd-0.16.1 pyzstd-0.14.4 texttable-1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObUSRDS-K4FH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn_pandas import DataFrameMapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vXxXWCVK-WV"
      },
      "source": [
        "import torch # For building the networks \n",
        "import torchtuples as tt # Some useful functions\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFezhPkllEG",
        "outputId": "bc7f57e5-8c9f-4d76-bbe6-d0fb313098cc"
      },
      "source": [
        "!pip install lifelines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.26.0-py3-none-any.whl (348 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.19.5)\n",
            "Collecting formulaic<0.3,>=0.2.2\n",
            "  Downloading formulaic-0.2.4-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 30 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 40 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 51 kB 45.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (3.2.2)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from lifelines) (1.1.5)\n",
            "Collecting autograd-gamma>=0.3\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines) (0.16.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines) (1.12.1)\n",
            "Collecting interface-meta>=1.2\n",
            "  Downloading interface_meta-1.2.4-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0->lifelines) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->lifelines) (2018.9)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4049 sha256=ec65fa92816500182b4491e77a335b652ed29e4f9405393419fc3d40bf6067a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/01/ee/1331593abb5725ff7d8c1333aee93a50a1c29d6ddda9665c9f\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, formulaic, autograd-gamma, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-0.2.4 interface-meta-1.2.4 lifelines-0.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie6ZrGrMt_Yh",
        "outputId": "baa92b29-749e-4334-b257-e0d08b52a780"
      },
      "source": [
        "!pip install openpyxl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (2.5.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KceS8ONguCXN",
        "outputId": "a44d7fd2-59b3-43ce-d999-4b47dcf91389"
      },
      "source": [
        "!pip install scikit-survival"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-survival\n",
            "  Downloading scikit-survival-0.15.0.post0.tar.gz (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 5.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/91/f0/047ce90bb831ab34ca287d1d23f0c61b6546cd89494566898c0e17516990/scikit-survival-0.15.0.post0.tar.gz#sha256=572c3ac6818a9d0944fc4b8176eb948051654de857e28419ecc5060bcc6fbf37 (from https://pypi.org/simple/scikit-survival/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpszko7qlx Check the logs for full command output.\u001b[0m\n",
            "  Downloading scikit-survival-0.14.0.tar.gz (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 53.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (1.1.5)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (1.2.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (2.7.3)\n",
            "Requirement already satisfied: scipy!=1.3.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (1.4.1)\n",
            "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (0.6.2.post0)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (1.0.31)\n",
            "Requirement already satisfied: scikit-learn<0.24,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scikit-survival) (1.0.1)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->scikit-survival) (2.1.4)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->scikit-survival) (2.0.7.post1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->scikit-survival) (0.70.12.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (0.1.5.post0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->scikit-survival) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->scikit-survival) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.21->scikit-survival) (1.15.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy>=1.0->scikit-survival) (0.3.4)\n",
            "Building wheels for collected packages: scikit-survival\n",
            "  Building wheel for scikit-survival (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-survival: filename=scikit_survival-0.14.0-cp37-cp37m-linux_x86_64.whl size=4061766 sha256=437cc4278362d18fd467f3aeac9b517d6b9e5acbbcce2547d695dfe871c1b5ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/3e/97/3722ba215d3dfe5429c1a7e4f24f535a3f46004fb29a16d505\n",
            "Successfully built scikit-survival\n",
            "Installing collected packages: scikit-survival\n",
            "Successfully installed scikit-survival-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU1xlQAAuIrH",
        "outputId": "e2645232-ef2c-4b06-e599-40b3e6ba8aa0"
      },
      "source": [
        "!pip install random-survival-forest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting random-survival-forest\n",
            "  Downloading random_survival_forest-0.8.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from random-survival-forest) (0.70.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from random-survival-forest) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from random-survival-forest) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from random-survival-forest) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from random-survival-forest) (1.0.1)\n",
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.7/dist-packages (from random-survival-forest) (0.26.0)\n",
            "Requirement already satisfied: formulaic<0.3,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from lifelines->random-survival-forest) (0.2.4)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines->random-survival-forest) (1.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines->random-survival-forest) (3.2.2)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.7/dist-packages (from lifelines->random-survival-forest) (0.5.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from lifelines->random-survival-forest) (1.4.1)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines->random-survival-forest) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines->random-survival-forest) (1.12.1)\n",
            "Requirement already satisfied: interface-meta>=1.2 in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines->random-survival-forest) (1.2.4)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines->random-survival-forest) (0.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines->random-survival-forest) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines->random-survival-forest) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines->random-survival-forest) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines->random-survival-forest) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0->lifelines->random-survival-forest) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->random-survival-forest) (2018.9)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->random-survival-forest) (0.3.4)\n",
            "Installing collected packages: random-survival-forest\n",
            "Successfully installed random-survival-forest-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgrrUPH0LPYJ"
      },
      "source": [
        "from pycox.datasets import metabric\n",
        "from pycox.models import LogisticHazard\n",
        "from pycox.models import PMF\n",
        "from pycox.models import DeepHitSingle\n",
        "from pycox.evaluation import EvalSurv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random_survival_forest import RandomSurvivalForest, concordance_index\n",
        "from lifelines import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from lifelines import CoxPHFitter\n",
        "from lifelines.utils import concordance_index as cindex\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_formats = ['svg']\n",
        "\n",
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.svm import FastSurvivalSVM, FastKernelSurvivalSVM\n",
        "from sksurv.util import Surv\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
        "\n",
        "from sksurv.datasets import load_veterans_lung_cancer\n",
        "from sksurv.column import encode_categorical\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from sksurv.svm import FastSurvivalSVM\n",
        "import warnings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i25ifJb3N-N8",
        "outputId": "391ecf36-8781-45f4-ead3-8d92d9b97f25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5VjumhN6Fw"
      },
      "source": [
        "def readDataset(DBName,yourLocation,sheetName , Head):  \n",
        "  path = yourLocation+'/'+DBName\n",
        "  readdf=pd.read_excel(path  ,sheet_name = sheetName , engine='openpyxl' ,header=Head)\n",
        "  return readdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbvs1eKBLh5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fb1a0b-1e25-40dd-9936-5a00d6aacdc8"
      },
      "source": [
        "nof = 5\n",
        "############################################\n",
        "outcome = 'Death'  ### 'Distant'   'Death'   'Locoregional'   'Progression'\n",
        "version = 'V4'   ### 'V3'   'V4'   'V2'\n",
        "METHODnAME = 'SVM'   ####  method name\n",
        "loc = \"/gdrive/MyDrive/FSA_FEA_DrGaemi/Hector_Final/Dataset/\"\n",
        "# loc = \"/gdrive/MyDrive/FSA_FEA_DrGaemi/Hector408/Datasets/\"\n",
        "\n",
        "yourLocation = loc+outcome.lower()+'/'+outcome+version\n",
        "############################################\n",
        "listOfDataset = os.listdir(yourLocation)\n",
        "Noutcome = 1\n",
        "listOfDataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pca.xlsx',\n",
              " 'kernel_pca.xlsx',\n",
              " 'tsne.xlsx',\n",
              " 'fa.xlsx',\n",
              " 'isomap.xlsx',\n",
              " 'sammon.xlsx',\n",
              " 'landmark_isomap.xlsx',\n",
              " 'diffusion_maps.xlsx',\n",
              " 'mds.xlsx',\n",
              " 'lle.xlsx',\n",
              " 'spe.xlsx',\n",
              " 'gplvm.xlsx',\n",
              " 'sne.xlsx',\n",
              " 'sym_sne.xlsx',\n",
              " 'autoencoder.xlsx',\n",
              " 'cfs.xlsx',\n",
              " 'fsv.xlsx',\n",
              " 'laplacian.xlsx',\n",
              " 'dgufs.xlsx',\n",
              " 'lasso.xlsx',\n",
              " 'fsasl.xlsx',\n",
              " 'relieff.xlsx',\n",
              " 'ufsol.xlsx',\n",
              " 'llcfs.xlsx',\n",
              " 'udfs.xlsx',\n",
              " 'mrmr.xlsx']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFKYF5hy1uqD"
      },
      "source": [
        "# from sksurv.datasets import load_veterans_lung_cancer\n",
        "# from sksurv.column import encode_categorical\n",
        "# data_x, y = load_veterans_lung_cancer()\n",
        "# x = encode_categorical(data_x)\n",
        "# x\n",
        "# print(y)\n",
        "# print(len(y))\n",
        "# print(type(y))\n",
        "# print(y[1])\n",
        "# print(type(y[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmo7dUlHxTY5"
      },
      "source": [
        "def score_survival_model(model, X, y):\n",
        "    prediction = model.predict(X)\n",
        "    result = concordance_index_censored(y['Progression'], y['Progression free survival'], prediction)\n",
        "    return result[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffl-PCikqKhh",
        "outputId": "3036bb78-61cb-440b-9bca-35dd4e527b87"
      },
      "source": [
        "ll = len(listOfDataset)\n",
        "DatasetResult = []\n",
        "####################################################\n",
        "DatasetPredictMatrix = []\n",
        "####################################################\n",
        "for i in range(0 , ll):\n",
        "  filename = listOfDataset[i]\n",
        "  print(filename)\n",
        "  readdf = readDataset(filename,yourLocation,'Data',None) \n",
        "  columnName = readdf.columns\n",
        "  # print(readdf)\n",
        "\n",
        "  readdf_Duration = readDataset(filename,yourLocation,'Output',None) \n",
        "  columnName_Duration = readdf_Duration.columns\n",
        "  # print(readdf_Duration)\n",
        "\n",
        "  readdf_external = readdf.iloc[readdf_Duration.shape[0]:,]\n",
        "  readdf = readdf.iloc[0:readdf_Duration.shape[0],]\n",
        "  # print(readdf_external)\n",
        "\n",
        "  readdf_Death = readDataset('Output.xlsx',loc,'Sheet1',0) \n",
        "  readdf_Death = readdf_Death.iloc[:,1:]\n",
        "  columnName_Death = readdf_Death.columns\n",
        "  # print(readdf_Death)\n",
        "  readdf_Death.replace({0: False, 1: True}, inplace=True)\n",
        "\n",
        "  target = [tuple(x) for x in readdf_Death.to_numpy()]\n",
        "  target = np.asarray(target , dtype=[(columnName_Death[0], '?'), (columnName_Death[1], '<f8')] )\n",
        "\n",
        "  n = Noutcome*(-2)\n",
        "  outcomeResult = []\n",
        "# ####################################################\n",
        "  outcomePredictMatrix = []\n",
        "# ####################################################\n",
        "  for j in range(0,Noutcome):\n",
        "\n",
        "    folds_Cindex = []\n",
        "# ####################################################\n",
        "    FoldsPredictMatrix = []\n",
        "# ####################################################\n",
        "\n",
        "    estimator = FastSurvivalSVM(max_iter=1000, tol=1e-6, random_state=0 )\n",
        "    param_grid = {'alpha': 2. ** np.arange(-12, 13, 2),\n",
        "                  'optimizer': ['avltree' , 'direct-count' ,'PRSVM'  ,'rbtree'  , 'simple' ]\n",
        "                  }    \n",
        "    gcv = GridSearchCV(estimator, param_grid, scoring=score_survival_model,\n",
        "                      n_jobs=4, iid=False, refit=False,\n",
        "                      cv=nof)\n",
        "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "    gcv = gcv.fit(readdf, target) \n",
        "    best_parameters = gcv.best_params_\n",
        "    print(best_parameters)\n",
        "    al = best_parameters['alpha']\n",
        "    op = best_parameters['optimizer']\n",
        "    best_score = gcv.best_score_\n",
        "    print(best_score)\n",
        "\n",
        "\n",
        "    fastsvm = FastSurvivalSVM( alpha=al, optimizer=op,  max_iter=1000, tol=1e-6, random_state=0 )\n",
        "    fastsvm.fit(readdf, target)\n",
        "    prediction=fastsvm.predict(readdf_external)\n",
        "    FoldsPredictMatrix.append(prediction)\n",
        "\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "    outcomeResult.append(best_score)\n",
        "####################################################\n",
        "    outcomePredictMatrix.append(FoldsPredictMatrix)\n",
        "####################################################\n",
        "\n",
        "  print('-------------------------',i,'-------------------------')\n",
        "  DatasetResult.append(outcomeResult)\n",
        "####################################################\n",
        "  DatasetPredictMatrix.append(outcomePredictMatrix)   \n",
        "#################################################### "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pca.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.7529049534056874\n",
            "------------------------- 0 -------------------------\n",
            "kernel_pca.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.5565613412266492\n",
            "------------------------- 1 -------------------------\n",
            "tsne.xlsx\n",
            "{'alpha': 4096.0, 'optimizer': 'direct-count'}\n",
            "0.715558241979824\n",
            "------------------------- 2 -------------------------\n",
            "fa.xlsx\n",
            "{'alpha': 0.0009765625, 'optimizer': 'rbtree'}\n",
            "0.7492415181531278\n",
            "------------------------- 3 -------------------------\n",
            "isomap.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.7350115215017153\n",
            "------------------------- 4 -------------------------\n",
            "sammon.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.7527190391195632\n",
            "------------------------- 5 -------------------------\n",
            "landmark_isomap.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.693340281791998\n",
            "------------------------- 6 -------------------------\n",
            "diffusion_maps.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.7413424588351404\n",
            "------------------------- 7 -------------------------\n",
            "mds.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.7529049534056874\n",
            "------------------------- 8 -------------------------\n",
            "lle.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.718255297032986\n",
            "------------------------- 9 -------------------------\n",
            "spe.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.5842327873496015\n",
            "------------------------- 10 -------------------------\n",
            "gplvm.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.6614052960968294\n",
            "------------------------- 11 -------------------------\n",
            "sne.xlsx\n",
            "{'alpha': 0.000244140625, 'optimizer': 'avltree'}\n",
            "0.7243288684335843\n",
            "------------------------- 12 -------------------------\n",
            "sym_sne.xlsx\n",
            "{'alpha': 0.00390625, 'optimizer': 'avltree'}\n",
            "0.49229973132507315\n",
            "------------------------- 13 -------------------------\n",
            "autoencoder.xlsx\n",
            "{'alpha': 1024.0, 'optimizer': 'avltree'}\n",
            "0.7472884915607306\n",
            "------------------------- 14 -------------------------\n",
            "cfs.xlsx\n",
            "{'alpha': 0.0009765625, 'optimizer': 'avltree'}\n",
            "0.7383216585330895\n",
            "------------------------- 15 -------------------------\n",
            "fsv.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zh4nE7VYmIq",
        "outputId": "2c917d84-e665-4f57-92aa-de54a429babd"
      },
      "source": [
        "##################################################\n",
        "\n",
        "# dirName = loc+ \"/Results/\"+outcome+\"/\"+METHODnAME\n",
        "# if not os.path.exists(dirName):\n",
        "#   os.mkdir(dirName)\n",
        "\n",
        "max = 0\n",
        "index = -1\n",
        "# filepath = dirName+\"/Results_\"+version+\".txt\"\n",
        "\n",
        "# file = open(filepath, \"w\")\n",
        "for i in range(0 , ll):\n",
        "  out = str(listOfDataset[i]) + ' -> mean : ' + str(np.mean(DatasetResult[i][0])) + ' -> std : ' + str(np.std(DatasetResult[i][0]))+'\\n'\n",
        "  print(out)\n",
        "  # file.write(out)\n",
        "  if max < np.mean(DatasetResult[i][0]):\n",
        "    max = np.mean(DatasetResult[i][0])\n",
        "    index = i\n",
        "\n",
        "print('\\n\\n\\n\\n')\n",
        "print('BestResult -->  ' ,listOfDataset[index] , ' -> mean : ' , np.mean(DatasetResult[index][0]) , ' -> std : ' , np.std(DatasetResult[index][0]))\n",
        "# file.close()\n",
        "##################################################\n",
        "# np.std(DatasetResult[0][0])\n",
        "# DatasetResult[dataset][outcome][fold]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kernel_pca.xlsx -> mean : 0.6852529932048335 -> std : 0.0\n",
            "\n",
            "pca.xlsx -> mean : 0.6995747261640197 -> std : 0.0\n",
            "\n",
            "tsne.xlsx -> mean : 0.7175314594954402 -> std : 0.0\n",
            "\n",
            "fa.xlsx -> mean : 0.697528140576149 -> std : 0.0\n",
            "\n",
            "sammon.xlsx -> mean : 0.692112964936886 -> std : 0.0\n",
            "\n",
            "landmark_isomap.xlsx -> mean : 0.6683402099404996 -> std : 0.0\n",
            "\n",
            "isomap.xlsx -> mean : 0.7017731236802506 -> std : 0.0\n",
            "\n",
            "mds.xlsx -> mean : 0.6995747261640197 -> std : 0.0\n",
            "\n",
            "diffusion_maps.xlsx -> mean : 0.6405251689774991 -> std : 0.0\n",
            "\n",
            "lle.xlsx -> mean : 0.6198924056278633 -> std : 0.0\n",
            "\n",
            "spe.xlsx -> mean : 0.48477433465988334 -> std : 0.0\n",
            "\n",
            "gplvm.xlsx -> mean : 0.6241523826176387 -> std : 0.0\n",
            "\n",
            "sne.xlsx -> mean : 0.6457241633641126 -> std : 0.0\n",
            "\n",
            "sym_sne.xlsx -> mean : 0.6046634404599739 -> std : 0.0\n",
            "\n",
            "autoencoder.xlsx -> mean : 0.7215370406362942 -> std : 0.0\n",
            "\n",
            "cfs.xlsx -> mean : 0.6696624299413532 -> std : 0.0\n",
            "\n",
            "dgufs.xlsx -> mean : 0.7176991128461591 -> std : 0.0\n",
            "\n",
            "fsasl.xlsx -> mean : 0.6591872138479583 -> std : 0.0\n",
            "\n",
            "laplacian.xlsx -> mean : 0.6508766693541929 -> std : 0.0\n",
            "\n",
            "mrmr.xlsx -> mean : 0.701313002214289 -> std : 0.0\n",
            "\n",
            "lasso.xlsx -> mean : 0.6792619460510463 -> std : 0.0\n",
            "\n",
            "fsv.xlsx -> mean : 0.6387774372535769 -> std : 0.0\n",
            "\n",
            "llcfs.xlsx -> mean : 0.6891116094860374 -> std : 0.0\n",
            "\n",
            "relieff.xlsx -> mean : 0.698872662901741 -> std : 0.0\n",
            "\n",
            "udfs.xlsx -> mean : 0.6892802359625283 -> std : 0.0\n",
            "\n",
            "ufsol.xlsx -> mean : 0.6030754671305021 -> std : 0.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "BestResult -->   autoencoder.xlsx  -> mean :  0.7215370406362942  -> std :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZmCvj5xa6oP"
      },
      "source": [
        "# DatasetResult[2][0]\n",
        "\n",
        "# res = DatasetPredictMatrix[2][0][0]\n",
        "# # res\n",
        "vvb0 = pd.DataFrame(DatasetPredictMatrix[2][0][0],columns=['tsne'])\n",
        "vvb1 = pd.DataFrame(DatasetPredictMatrix[6][0][0],columns=['isomap'])\n",
        "vvb2 = pd.DataFrame(DatasetPredictMatrix[14][0][0],columns=['AA'])\n",
        "vvb3 = pd.DataFrame(DatasetPredictMatrix[16][0][0],columns=['DGUFS'])\n",
        "vvb4 = pd.DataFrame(DatasetPredictMatrix[19][0][0],columns=['MRMR'])\n",
        "\n",
        "RES = pd.concat([vvb0, vvb1 , vvb2,vvb3,vvb4], axis=1)\n",
        "\n",
        "RES.to_csv(\"/gdrive/MyDrive/svm_RESULT.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mHFIq_R_P6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}